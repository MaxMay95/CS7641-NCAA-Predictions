{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means for Clustering (Alejandro)\n",
    "\n",
    "As we mentioned before, the NCAA tournament divides the 64 qualified teams into 16 different seed, according to their \"performance\" during the season. In reality, judges pick the seeds so one could argue that there's some degree of subjectivity to their choices and how teams should be seeding according to their statistics for that season. Our goal here is to quantify that subjectivity using unsupervised learning, specifically two different versions of the K Means Algorithm\n",
    "\n",
    "### Regular K-Means\n",
    "\n",
    "First, let's define as Regular K-Means, the algorithm available in the Python package scikit learn. We decided to start with the data from year 2018. Initially, we sought to separate the teams into two separate clusters: one for qualified teams and the other for unqualified ones using the regular K-Means algorithm. We used all 14 principal components from our transformed statistics when computing the Euclidean distance in the algorithm, thus accounting for 100% of the variance. We obtained the following results (original data plotted as contrast) \n",
    "\n",
    "    Introduce Regular_KMeans_AllTeams_2018.png\n",
    "    Introduce AllTeams_PCA_2018.png\n",
    "\n",
    "Encouraged by the clear separation between the clusters, we decided to divide the qualified teams for the year 2018 by clustering the teams into 16 clusters (equivalent to 16 seeds) based on the all of the transformed statistics obtained with PCA. We obtained the following results\n",
    "\n",
    "    Introduce Regular_KMeans_2018_16Seeds.png\n",
    "    Introduce Qualified_PCA_2018_16Seeds.png\n",
    "    \n",
    "It seems like clustering was not very good. Specifically, the purity of the clustering hovers at **39.5%**. We hypothesized that decreasing the number of clusters to 4 (which corresponds into 1-4 seeds, 5-8 seeds, etc.) would yield better results\n",
    "\n",
    "    Introduce Regular_KMeans_2018_4Seeds.png\n",
    "    Introduce Qualified_PCA_2018_4Seeds.png\n",
    "    \n",
    "Here, purity was **56.1%**. Even though we achieved better results, we noticed another problem with the regular K-Means algorithm, specifically that number of points per cluster is not limited. For example, the number of datapoints in the last run were as follows:\n",
    "\n",
    "1. Cluster #1: 10\n",
    "2. Cluster #2: 15\n",
    "3. Cluster #3: 17\n",
    "4. Cluster #4: 22\n",
    "\n",
    "### Modified K-Means\n",
    "\n",
    "Given these limitations, we created a Modified KMeans algorithm that evenly divides datapoints across clusters. Specifically, the clusters prioritize having the minimum distance between a datapoint and the cluster center, discarding the points that are farther away. These points in turn are forced to belong to another cluster. The implementation looked as follows for both the cases of 16 and 4 clusters\n",
    "\n",
    "    Introduce Modified_KMeans_2018_16Seeds.png\n",
    "    Introduce Modified_KMeans_2018_4Seeds.png\n",
    "    \n",
    "When we looked at the purity of each clustering, we obtained slightly better results when compared to the regular K-Means algorithm. Specifically, we obtained a purity of **41.7%** for 16 seeds (compared to 39.5%) and **57.5%** (compared to 56.1%)\n",
    "\n",
    "We then decided to further test the performance of both clustering algorithms by using data for all available years in the dataset (2010-2018). We normalized the statistics to the corresponding season in order to minimize differences in performance across the years. Results of PCA are shown here for contrast against the clusters later on \n",
    "\n",
    "    Introduce Qualified_PCA_All_16Seeds.png\n",
    "    Introduce Qualified_PCA_All_4Seeds.png\n",
    "    \n",
    "Furthermore, these are the results of running both algorithms for 16 and 4 clusters respectively\n",
    "\n",
    "    Introduce Regular_KMeans_All_16Seeds.png\n",
    "    Introduce Modified_KMeans_All_16Seeds.png\n",
    "    \n",
    "    Introduce Regular_KMeans_All_4Seeds.png\n",
    "    Introduce Modified_KMeans_All_4Seeds.png\n",
    "    \n",
    "In terms of purity, we obtained the following measurements.\n",
    "\n",
    "1. 16 Seeds: 26.5% (Regular) vs. 26.1% (Modified)\n",
    "2. 4 Seeds: 54.9% (Regular) vs. 55.0% (Modified)\n",
    "\n",
    "It is important to recognize the limitations of the latter approach to unsupervised clustering. Given more data, it appears that both algorithms have the same performance. This spans from the prioritization of assignment of data points to a cluster. A careful observer would note that some points in the modified K-Means algorithm are far away from their cluster center. This points could be called \"outliers\", not being close enough to any cluster center and thus assigned by default to a the center that is closest to it that doesn't have all points assigned to it yet\n",
    "\n",
    "### Conclusive Remarks about Unsupervised Learning\n",
    "\n",
    "The results from both hierarchical clustering and K-Means seem to highlight the poor performance of unsupervised learning to predict the seeding positions for any given year. More complicated algorithms or more exhaustive data could yield to better results, but we expect those to only show marginal imporvements over the algorithms described here given the subjectivity of seeding assignment carried out by a group of judges\n",
    "\n",
    "**Include a transition statement to Supervised Learning**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
