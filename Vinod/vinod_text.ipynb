{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 564 instances with 12 features after PCA is applied with 99% variance retained. The dataset is split into Train and Test set in a 90:10 ratio. Training set is further divided with K fold cross validation. We chose a K value of 4.\n",
    "\n",
    "A fully connected neural network consists of a series of fully connected layers. Each layer has an input and an output dimension. An activation function is used to introduce non-linearity in each layer. The strength of every connection between layers is determined by it's respective weight which is the learnable parameter in the network. \n",
    "\n",
    "We used standard full connected neural network with two layers. The average train accuracy was 81.18, average validation accuracy was 0.75 and best model test accuracy was 0.72. The accuracies clearly indicate overfitting. \n",
    "\n",
    "![Results without dropout](https://github.gatech.edu/raw/hwilco6/CS7641-NCAA-Predictions/master/Vinod/vinod_results_without_dropout.png?token=AAAIIG7ZBQYEMDDH6HYH3K26UUVWO)\n",
    "\n",
    "We used Dropout regularization technique with keep probablity of 0.5 resulting in dropping of 50% of the nodes in the first two layer. The average training accuracy was 0.77 average validation accuracy was 0.76 and best model test accuracy was 0.81.\n",
    "\n",
    "![Results with dropout](https://github.gatech.edu/raw/hwilco6/CS7641-NCAA-Predictions/master/Vinod/vinod_results_with_dropout.png?token=AAAIIG2Y5ZIXJLFLX4GIYXK6UUVXO)\n",
    "\n",
    "Binary Cross Entropy loss funtion was used to measure loss at every iteration of training. The learning rate of 0.001 was found to be optiomal. We used Adam optimizer for gradient descent. The network performed best at around 100 iterations. Further training resulted in overfitting.\n",
    "\n",
    "After several iterations, the final neural network architecture consisted of the following layers:\n",
    "\n",
    "* Input layer: \n",
    "    - Feature size x 50, RELU Activation \n",
    "    - Dropout p = 0.5\n",
    "* Hidden layer 1: \n",
    "    - 50 x 50, RELU Activation\n",
    "    - Dropout p = 0.5\n",
    "* Output layer:\n",
    "    - 50 x 1, Sigmoid Activation\n",
    "    \n",
    "![NN Architecture](https://github.gatech.edu/raw/hwilco6/CS7641-NCAA-Predictions/master/Vinod/vinod_nn_architecture.png?token=AAAIIG5NE3IFHPOVKXJ32MC6UUVSE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
